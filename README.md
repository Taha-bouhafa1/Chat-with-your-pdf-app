# ğŸ§  Chat With Your PDF

A simple and efficient app to **interact with your PDF documents** using **Local Embeddings + RAG (Retrieval-Augmented Generation)**.

Built with:
- ğŸ§  `LangChain` for orchestration
- ğŸ” `Chroma` for vector search
- ğŸ’¬ `Gradio` for web UI
- ğŸ”— `HuggingFace` (MiniLM) for embeddings
- ğŸ¤– (Optional) Groq API for LLM responses

---

## ğŸš€ Features

- âœ… Upload any PDF and chat with its contents
- âœ… Automatically extracts, chunks, and embeds your document
- âœ… Vector search with ChromaDB
- âœ… Clean and lightweight Gradio UI
- âœ… Local embedding with HuggingFace models (no OpenAI key needed)
- âœ… Easily extendable to use **Groq**, **OpenAI**, or any LLM

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/yourusername/chat-with-your-pdf.git
cd chat-with-your-pdf

# Create a virtual environment
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
## ğŸ§ª Run the App
```
```bash
python main.py
```
Then open: http://localhost:7860
## ğŸ“‚ Project Structure
chat-with-your-pdf/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ pdf_loader.py         # Loads and chunks PDF text
â”‚   â”œâ”€â”€ vector_store.py       # Embeds and stores text in Chroma
â”‚   â”œâ”€â”€ qa_chain.py           # Runs LLM over retrieved chunks
â”‚
â”œâ”€â”€ main.py                   # Gradio UI
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md

## ğŸ’¡ Example Models

| Type             | Model Name                                        |
|------------------|--------------------------------------------------|
| Embedding Model  | `sentence-transformers/all-MiniLM-L6-v2`         |
| Chat Model (LLM) | `meta-llama/llama-4-scout-17b-16e-instruct` (via Groq) |

## ğŸ“Œ Future Improvements

- Add support for multiple PDFs  
- Chat memory / history  
- File download for summaries  
- Upload `.txt` or `.docx` support  

---

## ğŸ§‘â€ğŸ’» Author

**Taha Bouhafa**  
Big Data & AI Engineer | NLP & LLM Enthusiast
